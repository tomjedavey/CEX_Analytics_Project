### Manual Analysis and Recommendations Report of Dashboard Based Off Model Configurations and Data

## Objective and Explanation of This File and its Purpose:

This file is put in place to show a manual analysis and interpetation of the results of the pipelines built in this github repository in a way that will model the type of interpretation possible with the use of this repository. 

Of course, this project is a minimum viable version of what is possible in use of this data and in terms of what could be built with further CEX data available and in the context of actually putting this concept into use. Therefore, the output of this data science and analytics project is only a small part of what could be built. The ability of the stakeholder using this repository to input new data and utilise new configurations to gain updated analytics of a range of blockchains leads way to the possibility of a self-serve analytics making use of the models built. A feedback-based UEX is another possibility, utilising AI and the impact of stakeholders' opinions to constantly improve the value to key decision making available. More on these concepts is talked about in TLADs documentation along with the README; the main thing to note here is that this analysis report of the "model run" is simply to show how this analytics can be interpreted and what is possible for future developments and use of this repository and if it were to be actually utilised. 

Structure of this report:

1. Executive Summary
2. Business Initiative Context
3. Stakeholder Empathy
4. Modelling Business Entities Utilised
5. Mapping Analytic Score Analysis to Recommendations
6. Evaluation of further improvements possible


## 1. Executive Summary


The purpose of the production of these analytic scores and their interpretation in this report is to provide analytic value to a CEX through providing information related to the key decisions that affect a certain business initiative. The business initiative for a CEX being targeted here is to improve user retention and personalised engagement strategies for Centralised Crypto Exchanges (CEXs - user retention, churn prediction and behavioural segmentation) to increase fee revenue.

The way in which this aims to be acheived is through targeting the following use case to look at user segmentation based on wallet behavioural archetypes. This is likely to improve user retention and personalised engagement strategies as it allows a CEX stakeholder to identify a wallet by its types of behaviour and from there make sure that the strategies deployed on that user are best suited to the type of CEX user that they are, along with overall understanding of shifts in their user-base. Of course, in order to turn the functionality in this repository into use in this way, more CEX-specific data would be required to link wallets with users (proposing a number of considerations with privacy policies and more also), but this does not mean that the premise is not valuable to consider. 

In terms of the key findings of the output in this project with the displayed "model" configurations and data, it is clear to identify a number of "behavioural archetypes" of wallets where groups show similar data that relates to a type of behaviour that could be considered in key decision making. The archetypes being looked at in the report as examples include: "erratic speculators", "DeFi power users", and "omnichain explorers". Throughout the data and results displayed, there are a number of other possible groups to explored and a number of possible other analytic scores that could be built to do so, as is explained in later parts of this report. 


## 2. Business Initiative Context


When understanding and analysing the output of a data pipeline such as this repository's, it is vital to understand the business initiative being chased in order to take the right approach in interpreting the results of what has been produced. The business initiative in this case is to improve user retention and personalised engagement strategies for Centralised Crypto Exchanges (CEXs - user retention, churn prediction and behavioural segmentation) to increase fee revenue. 

User retention in this case refers to keeping a user utilising the services of a CEX and this is aimed to be improved through being looking at the nanoeconomics (individual behaviours and propensities) of the data and informing CEX stakeholders on potential strategies that target specific behaviours seen in groups of wallets/users in order to avoid churn and keep these users utilising that CEX. This of course then drives a more strong user base and increased revenues and growth of a CEX when this analytic value is utilised properly. 

When looking at KPIs that would be targeted to be improved given this business initiative and that could be tracked with the correct types of data, key areas include: churn rate (%) for all the users of a CEX, CEX retention by archetype, withdrawal-deposit ratio, reactivation attribution and more. This is explored in great depth throughout the TLADS canvases which essentially consider how to go about building a project with these types of goals by thinking in a actual business applicable way.


## 3. Stakeholder Empathy 


The analytic value produced and possible through interpretation of the output of this repository is designed with the premise of informing a wide range of CEX stakeholders (possible in actuality through improvements in data integration). Therefore, the following touches upon a number of these stakeholders and maps how the output of this project relates more specifically to each. This is explored in a pre-production stage in the TLADS canvases in this repository that shows a more broad view than this explanation which focuses on areas sepecific to the small portions of analytics possible that have been produced in the results being looked at. 

One of the most important stakeholders to consider given this use case is the head of user retention strategies. The key decisions that the results of this project aid of course is in this stakeholder deciding which users to deploy certain strategies on. An example of what this could look like given what has been produced is to potentially target "erratic speculators" (which are likely high churn risk) and curate watchlists to more volatile coins or deploy other similar strategies to take advantage of their typical propensities. This is explored in much greater depth in the actual recommendations and more later in this report. 

Additionally, another vital stakeholder to consider is those working in product management at a CEX. The way in which these analytics can assist these stakeholders is through informing on the types of groups (or "behavioural archetypes") with which to personalise the user interface and services of the CEX to. For example, it may be best for this team to build greater user interface to explore new DeFi protocols to target the "DeFi power users" group. 

And finally, another stakeholder to touch upon is the marketing and user engagement team. The way in which stakeholders in this team likely use the analytics possible with this project is slightly different to that of other stakeholders in that there is a greater opportunity to analyse temporal shifts in the overall behaviour of a set of wallets/users to know how to change marketing being used. To explain this better, if a CEX marketing team was to understand that the group of "omnichain explorers" was growing in the users seen in the CEX over time, then this may reflect a change in the overall crypto markets where more of this demographic of wallets and CEX users are likely to use a wider range of protocols, coins and applications. This could therefore drive the outbound marketing strategies to be more tailored to this type of behaviour seen in users. 

Of course, many more stakeholders would be impacted by the full integration of this project and the fulfilment of its potential, but the above is a great demonstration of the type of stuff that is possible as it stands. More is explored in the TLADS canvases (Thinking Like a Data Scientist, a method explained by Bill Schmarzo).


## 4. Modelling Businesses and Scores


The following is a brief explanation of the analytic scores (and an additional model produced) used in nanoeconomics of wallet data to identify groups that relate to certain "behavioural archetypes":

- **Behavioural Volatility Score**: The Behavioural Volatility Score quantifies how variable or erratic a wallet's transaction behavior is over time. It measures the inconsistency in transaction amounts and timing for each wallet. High scores indicate wallets with irregular, unpredictable activity, while low scores suggest regular, stable transaction patterns. The score is typically derived using statistical analysis of transaction histories, such as calculating the standard deviation or other measures of dispersion in transaction frequency and amounts. This helps identify users whose behavior deviates from the norm, which can be useful for segmentation, risk assessment, or anomaly detection. 

- **Revenue Proxy Score**: Estimates the potential revenue contribution of each wallet by combining several aspects of user activity. It is calculated as a weighted sum of three main components: transaction activity (frequency of transactions multiplied by their average value), DEX/DeFi engagement (the number of decentralized exchange and DeFi events, weighted by average transfer value), and bridge activity (the total volume transferred via bridges). By aggregating these factors, the score highlights wallets that are likely to be high-value users based on their transaction patterns and engagement with DeFi and cross-chain services. Of course, the key caveat to this analytic score is that in use of actual, valuable data this would be taken from a CEX's data and would be accurate. Therefore, this score is only produced to show how this key part of a dataset would be intended to be used in actuality.

- **Cross Domain Engagement Score**: The cross domain engagement score is a metric that quantifies how diversely a cryptocurrency wallet interacts across different event types or domains. It is calculated using Shannon entropy, which measures the unpredictability or diversity of event participation for each wallet. A score near 1 means the wallet's activity is evenly spread across many event types (high engagement diversity). A score near 0 means the wallet's activity is concentrated in few or just one event type (low engagement diversity). A key issue with this score explored throughout is the fact that an overwhelming amount of wallets show a cross domain engagement of 0, not because they have low engagement, but because they have no engagement with the event categories in the dataset. This is extremely important to remember in interpretation and a potential flaw to improve upon in reflection, despite still being useful in interpretation of wallets with cross domain engagement scores above 0.

- **Interaction Mode Score**: A median value is produced for each of DEX_EVENTS, CEX_EVENTS, BRIDGE_EVENTS and DEFI_EVENTS from clustering results where a cluster median for each feature is selected from the most prominant cluster for that event type. The distance score measures how much a wallet's behavior deviates from the median, after normalizing for feature variability and weighting by the wallet's activity profile. A higher score means the wallet acts more unusually compared to typical behavior, with the score reflecting both the size and importance of these differences. The typical behaviour being a value of an EVENT feature engagement that is prominant and high. A key issue with these scores is in production and complexity of interpretation, something that is reflected upon consistently; the score makes it more difficult to see whether a wallet's event value is 0 or more and doesn't add as much additional information about the wallet's position in comparison to the rest of the dataset as initially intended. However, this does not take away from the value of this score and is something used in reflection in later explanations.

- **Activity-Based Clustering (UMAP + HDBSCAN)**: Groups wallets into clusters based on their activity patterns using a two-step pipeline: UMAP for dimensionality reduction and HDBSCAN for density-based clustering. This model reveals natural groupings or archetypes in the user base, helping to identify segments with similar behaviors. A key thing to note in analysing this score is to understand that the clusters are still rough in their accuracy; although it it true that distributions of data show differences in activity level of wallets, some wallets from one cluster may be more/less active than that of another cluster in a particular area.

The above analytic scores are built in order to turn the raw data into more interpretable scores to be used by those looking at the analytic output produced. Making use of these scores, a key way of interpreting and utilising what is outputted is in identifying groups of wallets that show common propensities in each of the scores and informing key decision making with this. 


## 5. Mapping Analytic Score Recommendations to Analysis


The following takes on the process for which this report document is mainly defined to achieve; analysing the output of the pipeline with the "model" configurations and data in order to give clear examples of how the output of this project can be interpreted to use the described use case in achieving the described business intiative. The actual data that this is modelled on is described in data_description.md in the data folder of this repository, and the model configurations for this pipeline run being analysed are saved in this subfolder of the artifacts folder (Manual_Analysis_Report_and_Configurations).

The way in which this is structured is by looking at the overall data's analytic score distributions, followed by the three "behavioural archetypes" for which visualisations are produced in the dashboard, and from there linking to the analytic scores and clustering output. Of course there is a great deal of additional analysis and interpretations that can be gained by looking at the visualisations and statistics seen in the dashboard, but for the purpose of understanding the ways in which the output of this project can be interpreted only the "behavioural archetype" visualisations are analysed below:

- Overall data distributions: 

Looking at the initial analytic score distribution visualisations and their statistics, it is clear to see that a great deal show extreme variance (every dashboard visualisation is of the 5th to 95th percentile to accomodate this). The behavioural volatility score distribution shows a more normal distribution around a mean of 0.58, with a smaller peak at lower values. The cross domain engagement score shows the large majority of wallets to have a value close to 0, with rising proportions of wallets (from a count of wallets near zero just after the proportion around 0) as the cross domain score increases. The revenue score proxy shows a greater deal of the distribution at lower scales, with decreasing proportions as the revenue score proxy increases and extreme outliers at high values of revenue score proxy. And finally, across the interaction mode scores, all show a large majority around the distance values that represent a events value of 0, with median values for DEX_EVENTS, CEX_EVENTS, BRIDGE_EVENTS and DEFI_EVENTS of 29, 2, 29 and 12. However, value can be seen in terms of identifying groups by looking at the proportions of wallets that display values below these median values which produce a interaction mode less than these values. Regardless of the analytic value of this score, the flaws in its production provide ample opportunity for improvement in future versioning of this project, as explained in the relative areas and README.

- UMAP dimensionality reduction + HDBSCAN clustering results:

Taking a more in depth look at the results of this pipeline, the intended purpose of the model configurations was to be able to find a rough split based on activity. This therefore clusters wallets into two clusters (-1 being the produced noise) with fairly even populations (cluster 0 with 8713 and cluster 1 with 11390, 0.4% of wallets being noise). I won't explain the depths of how the clustering metrics work, but with the understanding that importance is seen in comparison between different runs, it can be said to take this clustering with a degree of skeptisism as although differences are shown in analytic score distributions per cluster, there is a large degree of variation. 

This does not invalidate the impact of these findings however, cluster 0 (deemed as on average lower activity) showed a distibution with peak to the right of the whole dataset with behavioural volatility and cluster 1 (average higher activity) showed a distribution to the left, displaying typical patterns for activity based clusters as a wallet with lesser activity is more irregular in their activity.

For the cross domain engagement score, cluster 0 showed a larger majority around 0 in comparison to cluster 1 which showed a larger proportion of wallets to display larger values. We can interpret this by simply understanding that cluster 0 again shows lower activity in that most wallets likely has no interaction with any event types, and cluster 1 has a higher activity and interact with more event types so have a higher cross domain engagement.
In relation to the revenue score proxy, as expected the lower activity (on average) cluster 0 wallets displayed a larger density of smaller values in comparison to cluster 1. This reflects the clear interpretation that the roughly lower activity cluster of wallets utilises CEX services less and therefore produces a smaller revenue individually. Of course, a key caveat to remember here is that in practice, with actual revenue per wallet data, this would reflect an accurate representation of this interpretation (the production of the revenue score proxy is simply to give example of use).

And finally, in looking at the various interaction mode scores (with DEX_EVENTS, CEX_EVENTS, DEFI_EVENTS and BRIDGE_EVENTS as our event types) it is clear to see that the clusters show a smaller relative difference compared to that of the other analytic scores. DEX_EVENTS interaction mode shows a much larger proportion of wallets in cluster 0 at a distance of 29 (events score of 0) compared to cluster 1 which shows a larger proportion of wallets displaying a positive events count. CEX_EVENTS interaction mode shows a much smaller difference here, with a small proportion more cluster 0 wallets at a distance of 2 (events count of 0) and a small proportion less for cluster 1. For BRIDGE_EVENTS interaction mode scores, cluster 0 shows a larger proportion at the lower ends of the score value (larger bridge events interaction) than cluster 1 (lower bridge events interaction); this can be interpreted as lower activity wallets having an average larger interaction with bridges. Lastly, looking into the DEFI_EVENTS interaction mode scores, cluster 0 shows a much larger proportion at a distance of 12 (indicating larger proportion of wallets with 0 interaction here) than that of the cluster 1, showing that the on-average lower activity wallets interact less with DeFi protocols. 

- Stable High-Value Transactors Visualisations:

The "Stable High-Value Traders" visualisations identify a behavioural archetype of wallets based on the filters of behavioural volatility score less than 0.5 and revenue score proxy greater than 2000, producing a filtered set of data accounting for 4.76% of the overall dataset. This aims to select wallets with stable behaviour and high value in terms of their revenue (measured by a proxy value in this case) individually to what would be a CEX with integration of the intended data. Of course, looking at the analytic scores on which filters are placed, in the behavioural volatility score and revenue proxy visualisations there lies strong truncation in the filtered data with distributions with peaks at low behavioural volatility scores and a revenue proxy of roughly 2500. This type of a "behavioural archetype" is largely just defined on two dimensions where no other analytic scores reflect characteristics of a "stable high-value trader" apart from those used in filtering. However, when referring to the cross domain engagement score, it is easy to see that the large majority of these wallets have a value of 0. This likely means that the wallets don't have low engagement, they likely have no engagement with the event types in the dataset (a nuance and flaw linked to throughout with this score) which means that these wallets on average show very higher transactions, but a lower proportion of interaction with the event types. This concept is clearly evidence when looking at the interaction mode scores, as in every case the distribution is overwhelmingly at the value at which there is a event value of 0. 

This clear interpretation of having a set of wallets that are stable (low behavioural volatility) with high transaction values provides a clear link to the use case and business intitive described. This archetype identified in the current version of the data is a segment of wallets (and users with future integration of the correct data) that allows for the opportunity of CEX stakeholders to tailor their offerings and strategy in terms of how these users interact with a CEX in order to reduce their churn and increase overall revenue. One recommendation of a way in which this could be achieved in terms of the stakeholder that is the head of user retention could offer users in this category reduced withdrawal fees, or similar, in order to increase loyalty and retention to valuable users. Of course this is only one strategy, but through use of temporal retention KPIs, the impact of this analytics could be measured in use in real life. In terms of using these visualisations with future data, tracking the suitability of these visualisations in terms of the plots described is a strong way to track how many wallets fit into this category and therefore provides information as to what you can do in different cases. 

- DeFi Power Users:

The "DeFi Power Users" visualisations identify a behavioural archetype of wallets based on one filter exploring propensity of a wallet to interact with DeFi protocols, a filter that the DEFI_EVENTS interaction mode must be less than or equal to 9 (less than 9 means that these wallets must have a ineraction with this event above or equal to 3, as the value this distance is measured from is a DeFi events interaction value of 12). This produces a segment of wallets worth 25.66% of the overall dataset. Of course when looking at the DeFi events interaction mode score visualisation, this clear segmentation of the data is seen with peaks of this distribution
at lower interaction mode values. In addition to this, desipite being a largely one-dimensional archetype in terms of what it consists of, the reactions of the distribution of the filtered wallets in other analytic scores provides more information about the type of wallets with high DeFi protocol interactions. This can be seen in having a behavioural volatility distribution to the left of that of the whole dataset, showing more stable and less volatile wallets in behaviour. Also, of course, a cross domain engagement score distribution away from 0; largely because a wallet with strong DeFi interaction cannot have low or no engagement here, evidencing a clear link that verified possible interpretation. Along with this, revenue proxy score shows that these wallets show a larger propensity to have stronger values which is likely as a result of strong events interactions and therefore higher fee revenue in these CEX services. This also links in to the fact that these wallets are more likely to have stronger engagement with one other event type, being DEX_EVENTS, and a lower interaction with other event types being CEX_EVENTS and BRIDGE_EVENTS. The lower interaction with these event categories is to be expected for this archetype also as they likely stay on one chain to interact with DeFi protocols and keep their value locked into the system. 

The above interpretations and understanding of what this archetype shows in terms of analytic scores provides clear opportunity to link into the selected business initiative and use case. In terms of being able to segment these wallets, this allows a CEX stakeholder to deploy certain strategies on these users as a result of their propensities in high DeFi interaction (which in turn lead to larger than average revenue proxy score and other areas described above). A good example of one of these strategies could be in terms of a key decision by someone working in product management at a CEX; this could be in the form of curating a user's UEX in order to promote more DeFi protocols and give more information on them. This would as a result promote larger usage of a this CEX more solely, promoting stronger user retention and revenue per wallet where it matters (achieving the defined business initiative through use of the defined use case).

- Omnichain Explorers:

The "omnichain explorers" behavioural archetype visualisations identify wallets based on a single filter of the cross domain engagement score being equal to or larger than 0.8 in each wallet. This produces a more broad segment than that of the other archetypes visualised, with 26.21% of the whole dataset being included in these filtered wallets; this broader segment leads to a different style of interpretation in terms of a link to possible key decisions based off this which is explored later in this explanation. Behavioural volatility for this distribution of wallets showed to be skewed slightly to the left compared to that of the whole dataset's distribution, this can likely be interpreted as being down to the fact that high cross domain engagement in these wallets implies consistent interaction with event categories in the data leading to a lower volatility. Of course, in the cross domanain engagement clear truncation is seen for this segment, with large peaks and consistent density at the higher values of this analytic score. In terms of the interaction mode score visualisations, those most worth interpreting in regards to this particular filter, the archetype wallets in DEX_EVENTS scored consistently lower distance values which indicates larger DEX usage. Likewise, DEFI_EVENTS showed a similar pattern with smaller interaction mode distances, indicating more usage of DeFi protocols as a result of having larger cross domain engagement. And finally, in interpreting the density of BRIDGE_EVENTS interaction mode, omnichain explorers wallets showed larger proportions only specfically at distance values of 24 to 27, indicating events scores between 3 and 5, where the whole dataset showed larger proportions at the other score values. 

These interpretations of these wallets having more consistent and larger engagement with the various events categories involved in this dataset allow for key links to the business initiative and use case in an added archetype of wallets from which the CEX stakeholder could tailor their strategy to. In this case, this selection of wallets is a larger proportion of the whole dataset (in comparison to the rest of the archetypes looked at with the current filters, of course filters can be changed for future analysis as mentioned belo) which means that this archetype may potentially be used more strongly specifically in addition to other filters or with other confluence to produce a strategy. An example of this could be in the case of a marketing and user engagement team member of a CEX sending out marketing and emails to these users to advertise new services specifically related to DeFi protocols, increasing use of the CEX and driving revenue related to these users.

- The useability more specifically in relation to these analytics with different configurations and data is something that is particularly important in terms of how this type of a dashboard shoult be utilised and interpreted. Additionally, a key consideration for future use and changes is in relation to changing the filters being used to identify these groups with different data and configurations in the analytic scores results themselved. Of course, both of these important areas are important to understand and think about and therefore essentially this project is set up with the intention of providing a number of behavioural archetypes visualisations (where the behavioural archetype can be identified through seeing patterns similar to those descibed in the above analysis) from which the data, configurations and filters can all be adjusted to find the same type of patterns in future use. Of course not all the identified archetypes will be prevelant in different data which is key to understand; and in addition to this, there is a great number of different archetypes not explored or looked into which also provide value in the same way which is the path that this project would go down in real life application with the right data flows. The purpose of what has been explored is to show how this type of analytics works in providing informational value to stakeholders at a CEX in making key decisions based off a selected business initiative and use case, the possibilities for what this could transpire into as a result of this are huge in quantity.


## 6. Evaluation of Further Improvements Possible


Touching upon what the end of the last section talks about, there is endless possibilities and opportunities in which additional analytic value could be produced to a CEX through use of these types of data analysis, data science and method of thinking. Therefore, the below goes through a quick reflection of the areas that particularly could have done with improvement from what has been built, my thought processes in relation to the production of some of these areas and an acknowledgement of where I have potentially taken the less-than-optimal method in producing an analytic score and what I learned as a result of it.

The purpose of producing analytic scores was to produce a "analytic profile" for each of the wallets in the dataset (as described in the TLADS book by Bill Schmarzo) where these analytic profiles would not only tell you about temporal changes across the whole dataset in their distributions, but also inform you about the likely propensities of a certain wallet and user based on similarities with other wallets. Analytic scores are built in order to produce an analytic profile that transforms the raw data for each wallet into something useable by a CEX stakeholder. 

Given the above context, key areas that I feel I took a less than optimal production method in attempting to acheieve the intended outcome can be seen in overcomplicating analytic scores that don't need as complex of a formula, as well as not taking into account difficulties in the extent of outliers and differences in the onchain crypto data being used in producing these analytic scores. A clear example of this is in the production of the cross domain engagement score, the concept behind what is trying to be achieved is sound and its intended application to the business intiative and use case is understandable. However, the method used fails to consider the fact that a large proportion of wallets have no engagement with any of the event types in the data, resulting in a large majority of wallets having a cross domain engagment of 0 but no added context as to whether these wallets have engaged with events in the data or not. The value in interpreting this is still there given this understanding, but this is an example of a flaw in this analytic score's production that could be improved in future iterations. 

Another key consideration aside from specific analytic scores is that not all analytic scores are on the same scale. Therefore, interpretation of the scores from the perspective of the CEX stakeholder or user of the project's output is confusing compared to what it could be. The perfect example of this is in the clustered data results; having a wallet with a cluster label does not tell the user anything unless they fully understand all interpretations and analytics of the clusters themselves. This could be improved with potentially even greater explanation or a stronger stakeholder and analytics team relationship in practicality, but this is still a damaging effect to the future possibility of self-serve analytics if this project were to be put into practice. 

In addition to the above, when looking at potential visualisations being looked at in the dashboard, there is no involvement of clustering pipeline results in the identification of "behavioural archtypes". Of course this would not take too long in implementation, but for the practice of giving intuition to the potential use to this type of a project I thought it best to not over-complicate the dashboard. 

To add to these improvements listed and explained, the interaction mode scores can be evaluated as likely overcomplicated in their process to achieve what was intended. The concept of what is used is a strong method, but likely as a result of my lack of exploratory data analysis and understanding of the data itself, this resulted in something that achieved would could have been achieved with the raw data, just with a comfusing and intricate process. The use of a median value for a "model" wallet in terms of interaction with a particular event type to be produced using clustering results is a far too complex system for the analysis acheived and does not work in the intended way with this data. If I were to re-approach this particular approach, I would take into more account understanding how to achieve the intended analytic value without over-complicating the way in which I do so. 

A number of other improvements and considerations of my methods are explained in other documentation (such as the README) in terms of how this project could work in future iterations or with integration of data that would be available in the case of actual application to a CEX's analytics.