data:
 raw_data_path: 'data/raw_data/initial_raw_data_polygon.csv' #**NEED TO MAKE SURE THAT THESE DIRECTORIES ARE CORRECT IN TERMS OF EACH FILE USING THIS CONFIG.YAML**
 processed_data_path: '/Users/tomdavey/Documents/GitHub/MLProject1/data/processed_data/AS_1_feature_data.csv'
 score_output_path: 'data/scores/AS_1_scores.csv'

preprocessing:
#SEE WHAT IS NEEDED AS PRODUCTION OF THE LINEAR REGRESSION FUNCTION IN TRAIN_MODEL.PY PROGRESSES THEN ADD THE RELEVANT CATEGORIES + CONFIGURATIONS HERE
  use_scaling: true

model:
 type: linear_regression
 fit_intercept: true
 normalize: true

features:
 dependent_variable: REVENUE_PROXY
 independent_variables:
  #volume features
  - LOG_AVG_TRANSFER
  - LOG_TOTAL_VOLUME
  - LOG_BRIDGE_VOLUME
  #Activity features
  - TX_PER_MONTH
  - TRADING_INTENSITY
  #Sophiptication features
  - PROTOCOL_EXPERTISE
  - METHOD_SOPHISTICATION
  - PROTOCOL_DIVERSITY
  - TOKEN_DIVERSITY
  #Stability features
  - WALLET_MATURITY_SCORE
  - CROSS_CHAIN_INTENSITY
  - BRIDGE_EFFICIENCY
  #Engagement features
  - DOMAIN_BREADTH
  - INTERACTION_DIVERSITY
  #Binary indicators
  - IS_BRIDGE_USER
  - IS_ADVANCED_USER
  - IS_HIGH_FREQUENCY
  - IS_MULTI_DOMAIN

train_test_split:
 test_size: 0.2
 random_state: 42

output:
 model_path: linear_regression_model.pkl #**DOES THIS WORK? - IF ANYTHING THIS IS THE MOST LIKELY LOCATION TO PRODUCE ERRORS**
 #**NEED TO FIGURE OUT HOW THIS ACTUALLY WORKS, WHAT THE ABOVE DOES IN TERMS OF THE RESULTS OF THE LINEAR REGRESSION, AND WHAT ELSE NEEDS TO BE ADDED HERE**
 #logs_path:
 #metrics_path:
 #predictions_path:
 #plots_dir:
 #feature_importance_path:
 #config_copy_path: