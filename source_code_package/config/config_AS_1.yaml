data:
 raw_data_path: 'data/raw_data/new_raw_data_polygon.csv' # Updated to use current dataset
 processed_data_path: '/Users/tomdavey/Documents/GitHub/MLProject1/data/processed_data/AS_1_feature_data.csv'
 score_output_path: 'data/scores/AS_1_scores.csv'

preprocessing:
#SEE WHAT IS NEEDED AS PRODUCTION OF THE LINEAR REGRESSION FUNCTION IN TRAIN_MODEL.PY PROGRESSES THEN ADD THE RELEVANT CATEGORIES + CONFIGURATIONS HERE
  use_scaling: true

model:
 type: linear_regression
 fit_intercept: true
 normalize: true

features:
  dependent_variable: REVENUE_PROXY
  independent_variables:
    # Volume features
    #- LOG_AVG_TRANSFER
    #- LOG_TOTAL_VOLUME
    #- LOG_BRIDGE_VOLUME
    # Activity features
    - TX_PER_MONTH
    #- TRADING_INTENSITY
    # Sophistication features
    #- PROTOCOL_EXPERTISE
    #- METHOD_SOPHISTICATION
    #- PROTOCOL_DIVERSITY
    #- TOKEN_DIVERSITY
    # Stability features
    #- WALLET_MATURITY_SCORE
    #- CROSS_CHAIN_INTENSITY
    #- BRIDGE_EFFICIENCY
    # Engagement features
    #- DOMAIN_BREADTH
    #- INTERACTION_DIVERSITY
    # Binary indicators
    #- IS_BRIDGE_USER
    #- IS_ADVANCED_USER
    #- IS_HIGH_FREQUENCY
    #- IS_MULTI_DOMAIN


train_test_split:
 test_size: 0.2
 random_state: 42

output: #careful here - this section is brought in in train_model.py and is used to save the model and results
 model_path: linear_regression_model.pkl #**DOES THIS WORK? - IF ANYTHING THIS IS THE MOST LIKELY LOCATION TO PRODUCE ERRORS**
 test_results_path: data/scores/AS_1_test_results.csv #**NEED TO MAKE SURE THAT THIS IS THE CORRECT PATH FOR THE TEST RESULTS CSV FILE**
 #**NEED TO FIGURE OUT HOW THIS ACTUALLY WORKS, WHAT THE ABOVE DOES IN TERMS OF THE RESULTS OF THE LINEAR REGRESSION, AND WHAT ELSE NEEDS TO BE ADDED HERE**
 #logs_path:
 #metrics_path:
 #predictions_path:
 #plots_dir:
 #feature_importance_path:
 #config_copy_path: